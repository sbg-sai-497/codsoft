{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKShtac4Ne7m",
        "outputId": "6666da07-eae4-4905-d536-c82b24be8bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the path to the Iris dataset CSV file: /content/archive (6).zip\n",
            "sepal_length    0\n",
            "sepal_width     0\n",
            "petal_length    0\n",
            "petal_width     0\n",
            "species         0\n",
            "dtype: int64\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        10\n",
            "Iris-versicolor       1.00      1.00      1.00         9\n",
            " Iris-virginica       1.00      1.00      1.00        11\n",
            "\n",
            "       accuracy                           1.00        30\n",
            "      macro avg       1.00      1.00      1.00        30\n",
            "   weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Predicted species for the new flower: Iris-setosa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Load the dataset (taking the CSV file path as user input)\n",
        "file_path = input(\"Please enter the path to the Iris dataset CSV file: \")\n",
        "\n",
        "# Read the dataset into a pandas DataFrame\n",
        "data = pd.read_csv('/content/archive (6).zip')\n",
        "\n",
        "# Step 2: Check for missing values\n",
        "print(data.isnull().sum())  # Check for missing values in each column\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "# Encode the 'species' column (target variable) into numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "data['species'] = label_encoder.fit_transform(data['species'])\n",
        "\n",
        "# Step 4: Split the dataset into features (X) and target (y)\n",
        "X = data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]  # Features\n",
        "y = data['species']  # Target variable\n",
        "\n",
        "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Feature scaling (Optional, but often improves model performance)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit and transform the training data\n",
        "X_test = scaler.transform(X_test)  # Only transform the test data\n",
        "\n",
        "# Step 6: Train a Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 8: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Display the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Step 9: Use the model to make predictions on new data (Example input)\n",
        "# Example: Predicting the species for a new flower with specific measurements\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2]]  # Example feature values (sepal_length, sepal_width, petal_length, petal_width)\n",
        "new_data_scaled = scaler.transform(new_data)  # Scale the new data using the same scaler\n",
        "prediction = model.predict(new_data_scaled)\n",
        "predicted_species = label_encoder.inverse_transform(prediction)  # Convert numeric prediction back to species name\n",
        "print(f\"Predicted species for the new flower: {predicted_species[0]}\")"
      ]
    }
  ]
}